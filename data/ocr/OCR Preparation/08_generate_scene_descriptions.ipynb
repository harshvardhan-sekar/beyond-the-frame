{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Scene Descriptions with Gemini Batch API\n",
    "\n",
    "---\n",
    "\n",
    "## How to Run This Notebook\n",
    "\n",
    "### Prerequisites\n",
    "1. Google Cloud Project with Vertex AI API enabled\n",
    "2. GCS Bucket with data uploaded:\n",
    "   - `gs://harshasekar-comics-data/training_sequences/train_sequences.pkl`\n",
    "   - `gs://harshasekar-comics-data/raw_panel_images/`\n",
    "3. Authentication configured\n",
    "\n",
    "### Steps\n",
    "\n",
    "| Step | Action | Time |\n",
    "|------|--------|------|\n",
    "| 1 | Run Part A (Setup) | 1 min |\n",
    "| 2 | Run Part B (Test 5 examples) | 2 min |\n",
    "| 3 | STOP - Share results with Claude | - |\n",
    "| 4 | If approved, run Part C (Build shards) | 10 min |\n",
    "| 5 | Run Part D (Upload & submit) | 5 min |\n",
    "| 6 | Run commands in Cloud Shell | 20-24 hrs |\n",
    "| 7 | Run Part E (Monitor) | - |\n",
    "| 8 | Run Part F (Download results) | 10 min |\n",
    "| 9 | Run Part G (Merge & upload) | 5 min |\n",
    "\n",
    "### Cost\n",
    "- Test job: ~$0.01\n",
    "- Full batch: ~$25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART A: Configuration\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready\n"
     ]
    }
   ],
   "source": [
    "# A1: Install dependencies (Colab)\n",
    "# !pip install -q google-cloud-storage google-cloud-aiplatform tqdm\n",
    "print(\"Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready\n"
     ]
    }
   ],
   "source": [
    "# A2: Authenticate (Colab)\n",
    "# from google.colab import auth\n",
    "# auth.authenticate_user()\n",
    "print(\"Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project: fluent-justice-478703-f8\n",
      "Bucket: harshasekar-comics-data\n",
      "Model: gemini-2.5-flash-lite\n"
     ]
    }
   ],
   "source": [
    "# A3: Configuration\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ID = \"fluent-justice-478703-f8\"\n",
    "LOCATION = \"us-central1\"\n",
    "BUCKET = \"harshasekar-comics-data\"\n",
    "\n",
    "GCS_SEQUENCES_PATH = \"training_sequences/train_sequences.pkl\"\n",
    "GCS_IMAGES_PREFIX = \"raw_panel_images\"\n",
    "GCS_BATCH_INPUT = \"batch_inputs/scene_descriptions\"\n",
    "GCS_BATCH_OUTPUT = \"scene_descriptions/outputs\"\n",
    "\n",
    "SHARD_SIZE = 35000\n",
    "MODEL = \"gemini-2.5-flash-lite\"\n",
    "\n",
    "WORKDIR = Path(\".\")\n",
    "SHARDS_DIR = WORKDIR / \"scene_desc_shards\"\n",
    "SHARDS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Project: {PROJECT_ID}\")\n",
    "print(f\"Bucket: {BUCKET}\")\n",
    "print(f\"Model: {MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from gs://harshasekar-comics-data/training_sequences/train_sequences.pkl\n",
      "Loaded 249,576 sequences\n"
     ]
    }
   ],
   "source": [
    "# A4: Load sequences\n",
    "import pickle\n",
    "from google.cloud import storage\n",
    "\n",
    "print(f\"Loading from gs://{BUCKET}/{GCS_SEQUENCES_PATH}\")\n",
    "\n",
    "client = storage.Client(project=PROJECT_ID)\n",
    "bucket_obj = client.bucket(BUCKET)\n",
    "blob = bucket_obj.blob(GCS_SEQUENCES_PATH)\n",
    "\n",
    "pkl_bytes = blob.download_as_bytes()\n",
    "sequences = pickle.loads(pkl_bytes)\n",
    "\n",
    "print(f\"Loaded {len(sequences):,} sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta: /scratch/bftl/hsekar/comics_project/data/images/0/2_0.jpg\n",
      "GCS:   gs://harshasekar-comics-data/raw_panel_images/0/2_0.jpg\n"
     ]
    }
   ],
   "source": [
    "# A5: Path conversion helper\n",
    "def delta_path_to_gcs_uri(delta_path: str) -> str:\n",
    "    path = Path(delta_path)\n",
    "    comic_no = path.parent.name\n",
    "    filename = path.name\n",
    "    return f\"gs://{BUCKET}/{GCS_IMAGES_PREFIX}/{comic_no}/{filename}\"\n",
    "\n",
    "# Test\n",
    "test_path = sequences[0]['context'][0]['image_path']\n",
    "print(f\"Delta: {test_path}\")\n",
    "print(f\"GCS:   {delta_path_to_gcs_uri(test_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt template:\n",
      "You are looking at 6 consecutive panels from a comic book.\n",
      "\n",
      "Here is the text from each panel:\n",
      "{context_dialogue}\n",
      "Panel 6: {target_dialogue}\n",
      "\n",
      "Based on what you see in these panels, describe what happens in Panel 6 (the last panel).\n",
      "\n",
      "Include the scene, any dialogue, and sound effects.\n",
      "\n",
      "Write your response as a single flowing paragraph. Do not use bullet points, \n",
      "numbered lists, bold text, asterisks, or any markdown formatting. \n",
      "Weave the dialogue naturally into your description.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A6: Prompt template (matches fine-tuning prompt exactly)\n",
    "SCENE_DESCRIPTION_PROMPT = '''You are looking at 6 consecutive panels from a comic book.\n",
    "\n",
    "Here is the text from each panel:\n",
    "{context_dialogue}\n",
    "Panel 6: {target_dialogue}\n",
    "\n",
    "Based on what you see in these panels, describe what happens in Panel 6 (the last panel).\n",
    "\n",
    "Include the scene, any dialogue, and sound effects.\n",
    "\n",
    "Write your response as a single flowing paragraph. Do not use bullet points, \n",
    "numbered lists, bold text, asterisks, or any markdown formatting. \n",
    "Weave the dialogue naturally into your description.\n",
    "\n",
    "'''\n",
    "\n",
    "print(\"Prompt template:\")\n",
    "print(SCENE_DESCRIPTION_PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART B: Test Job (5 Examples)\n",
    "---\n",
    "\n",
    "**Run this before the full batch to verify output quality!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready: gemini-2.5-flash-lite\n"
     ]
    }
   ],
   "source": [
    "# B1: Setup Gemini\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "import time\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "model = GenerativeModel(MODEL)\n",
    "print(f\"Model ready: {MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 5 sequences: [167621, 29184, 6556, 194393, 72097]\n",
      "\n",
      "[1/5] Comic 992, Story 0...\n",
      "   OK\n",
      "[2/5] Comic 191, Story 3...\n",
      "   OK\n",
      "[3/5] Comic 40, Story 0...\n",
      "   OK\n",
      "[4/5] Comic 1149, Story 5...\n",
      "   OK\n",
      "[5/5] Comic 469, Story 0...\n",
      "   OK\n",
      "\n",
      "Done: 5/5 successful\n"
     ]
    }
   ],
   "source": [
    "# B2: Run test\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "test_indices = random.sample(range(len(sequences)), 5)\n",
    "test_sequences = [sequences[i] for i in test_indices]\n",
    "\n",
    "print(f\"Testing {len(test_sequences)} sequences: {test_indices}\\n\")\n",
    "\n",
    "test_results = []\n",
    "\n",
    "for i, seq in enumerate(test_sequences):\n",
    "    print(f\"[{i+1}/5] Comic {seq['comic_no']}, Story {seq['story_idx']}...\")\n",
    "    \n",
    "    # Build context dialogue\n",
    "    context_texts = seq.get('context_texts', [])\n",
    "    context_parts = []\n",
    "    for j, text in enumerate(context_texts, 1):\n",
    "        if text and text.strip():\n",
    "            context_parts.append(f\"Panel {j}: {text.strip()[:400]}\")\n",
    "        else:\n",
    "            context_parts.append(f\"Panel {j}: [No text]\")\n",
    "    context_dialogue = \"\\n\".join(context_parts)\n",
    "    \n",
    "    # Target dialogue\n",
    "    target_dialogue = seq.get('target_text', '') or '[No text]'\n",
    "    target_dialogue = target_dialogue.strip()[:500] if target_dialogue.strip() else '[No text]'\n",
    "    \n",
    "    # Fill prompt\n",
    "    prompt = SCENE_DESCRIPTION_PROMPT.format(\n",
    "        context_dialogue=context_dialogue,\n",
    "        target_dialogue=target_dialogue\n",
    "    )\n",
    "    \n",
    "    # Build image parts\n",
    "    image_parts = []\n",
    "    for panel in seq['context']:\n",
    "        gcs_uri = delta_path_to_gcs_uri(panel['image_path'])\n",
    "        image_parts.append(Part.from_uri(gcs_uri, mime_type=\"image/jpeg\"))\n",
    "    target_gcs_uri = delta_path_to_gcs_uri(seq['target']['image_path'])\n",
    "    image_parts.append(Part.from_uri(target_gcs_uri, mime_type=\"image/jpeg\"))\n",
    "    \n",
    "    # Call Gemini\n",
    "    try:\n",
    "        response = model.generate_content(\n",
    "            image_parts + [prompt],\n",
    "            generation_config={\"temperature\": 0.3, \"top_p\": 0.9}\n",
    "        )\n",
    "        scene_description = response.text.strip()\n",
    "        test_results.append({\n",
    "            'index': test_indices[i],\n",
    "            'comic_no': seq['comic_no'],\n",
    "            'story_idx': seq['story_idx'],\n",
    "            'target_text_ocr': target_dialogue,\n",
    "            'scene_description': scene_description,\n",
    "            'status': 'success'\n",
    "        })\n",
    "        print(f\"   OK\")\n",
    "    except Exception as e:\n",
    "        test_results.append({\n",
    "            'index': test_indices[i],\n",
    "            'comic_no': seq['comic_no'],\n",
    "            'story_idx': seq['story_idx'],\n",
    "            'target_text_ocr': target_dialogue,\n",
    "            'error': str(e),\n",
    "            'status': 'failed'\n",
    "        })\n",
    "        print(f\"   ERROR: {e}\")\n",
    "    \n",
    "    time.sleep(1)\n",
    "\n",
    "print(f\"\\nDone: {sum(1 for r in test_results if r['status']=='success')}/5 successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEST RESULTS\n",
      "======================================================================\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "TEST 1/5 | Index: 167621 | Comic: 992, Story: 0\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "\n",
      "TARGET TEXT (OCR):\n",
      "  THE DOLL MAN GOES INTO ACTION... HEADS UP!! WHAT TH.. !!?\n",
      "\n",
      "GEMINI SCENE DESCRIPTION:\n",
      "  In Panel 6, the scene shifts to a dramatic moment as the text announces \"THE DOLL MAN GOES INTO ACTION...\". A man with a shocked expression, his mouth agape, looks upwards. Above him, a superhero figure, presumably the Doll Man, is in mid-air, his cape flowing behind him. The Doll Man shouts \"HEADS UP!!\", and the shocked man exclaims \"WHAT TH.. !!?\". There are no sound effects in this panel.\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "TEST 2/5 | Index: 29184 | Comic: 191, Story: 3\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "\n",
      "TARGET TEXT (OCR):\n",
      "  BUT A FEW BLOCKS AWAY, AMAY APPEARS AGAIN, AND HAILS A TAXI- TO THE AIRPORT- AND HURRY!\n",
      "\n",
      "GEMINI SCENE DESCRIPTION:\n",
      "  In Panel 6, a few blocks away from the previous scene, a man, presumably the one referred to as \"AMAY\" in the narration, reappears and hails a taxi. He is seen stepping into the open door of a red taxi, and his dialogue, enclosed in a speech bubble, instructs the driver, \"TO THE AIRPORT- AND HURRY!\". The panel depicts the man entering the vehicle, ready to make his escape.\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "TEST 3/5 | Index: 6556 | Comic: 40, Story: 0\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "\n",
      "TARGET TEXT (OCR):\n",
      "  YOU MEAN THERE'S NO SIGNS? NO, WHOEVER THE RUSTLER IS, HE'S PICKIN' ONLY THE BEST STEERS AND RUNNIN' 'EM OFF ONE AT A TIME!\n",
      "\n",
      "GEMINI SCENE DESCRIPTION:\n",
      "  In Panel 6, Red, the rabbit, stands facing the Sheriff, a dog with a walrus mustache, outside a building. Red asks, \"You mean, there's no signs?\" The Sheriff replies, \"No, whoever the rustler is, he's pickin' only the best steers and runnin' 'em off one at a time!\"\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "TEST 4/5 | Index: 194393 | Comic: 1149, Story: 5\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "\n",
      "TARGET TEXT (OCR):\n",
      "  NO QUESTIONS, MISTER! I CANNOT TELL YOU WHY, BUT I MUST HAVE IT BACK! IT IS LIFE OR DEATH - I WILL PAY YOU TWICE WHAT YOU GAVE ME FOR IT! HMM- WELL, OKAY! IF YOU WANT IT THAT BADLY! ON GO MO WO AL TH\n",
      "\n",
      "GEMINI SCENE DESCRIPTION:\n",
      "  In Panel 6, the scene shifts to an interior setting where the seller, looking distressed, pleads with Sam Graves, saying \"NO QUESTIONS, MISTER! I CANNOT TELL YOU WHY, BUT I MUST HAVE IT BACK! IT IS LIFE OR DEATH - I WILL PAY YOU TWICE WHAT YOU GAVE ME FOR IT!\" Sam, appearing thoughtful, responds with \"HMM- WELL, OKAY! IF YOU WANT IT THAT BADLY!\" The panel also shows the seller with his hands clasped together, and Sam looking at him with a serious expression. There are no sound effects in this panel.\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "TEST 5/5 | Index: 72097 | Comic: 469, Story: 0\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "\n",
      "TARGET TEXT (OCR):\n",
      "  BUT JEAN DOES NOT APPEAR! THEY ENTER--AND... YOU'RE MISTAKEN! YOUR FRIEND DIDN'T COME TO THIS STORE! YOU'RE LYING... SHE MUST BE HERE! UNLESS YOU LEAVE AT ONCE, I SHALL CALL THE POLICE!\n",
      "\n",
      "GEMINI SCENE DESCRIPTION:\n",
      "  In Panel 6, the scene shifts to inside the store, where the two masked figures, Tim and Bob, have entered and are confronting a saleswoman and a store manager. The saleswoman insists, \"You're mistaken! Your friend didn't come to this store!\" Bob, however, is insistent, exclaiming, \"You're lying... she must be here!\" The manager, growing impatient, warns them, \"Unless you leave at once, I shall call the police!\" This confrontation occurs in front of a display featuring a red dress on a mannequin, the very dress Jean was interested in.\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "END OF TEST RESULTS\n"
     ]
    }
   ],
   "source": [
    "# B3: Display results - COPY THIS OUTPUT AND SHARE WITH CLAUDE\n",
    "print(\"=\"*70)\n",
    "print(\"TEST RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, result in enumerate(test_results):\n",
    "    print(f\"\\n{'─'*70}\")\n",
    "    print(f\"TEST {i+1}/5 | Index: {result['index']} | Comic: {result['comic_no']}, Story: {result['story_idx']}\")\n",
    "    print(f\"{'─'*70}\")\n",
    "    \n",
    "    print(f\"\\nTARGET TEXT (OCR):\")\n",
    "    print(f\"  {result['target_text_ocr']}\")\n",
    "    \n",
    "    if result['status'] == 'success':\n",
    "        print(f\"\\nGEMINI SCENE DESCRIPTION:\")\n",
    "        print(f\"  {result['scene_description']}\")\n",
    "    else:\n",
    "        print(f\"\\nERROR: {result.get('error')}\")\n",
    "\n",
    "print(f\"\\n{'─'*70}\")\n",
    "print(\"END OF TEST RESULTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to test_results.json\n"
     ]
    }
   ],
   "source": [
    "# B4: Save test results\n",
    "import json\n",
    "with open(WORKDIR / \"test_results.json\", 'w') as f:\n",
    "    json.dump(test_results, f, indent=2, default=str)\n",
    "print(\"Saved to test_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# STOP - Share test results with Claude before continuing!\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART C: Build JSONL Shards\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request builder ready\n"
     ]
    }
   ],
   "source": [
    "# C1: Request builder\n",
    "import json\n",
    "\n",
    "def make_scene_request(seq_idx, sequence):\n",
    "    context_texts = sequence.get('context_texts', [])\n",
    "    context_parts = []\n",
    "    for i, text in enumerate(context_texts, 1):\n",
    "        if text and text.strip():\n",
    "            context_parts.append(f\"Panel {i}: {text.strip()[:400]}\")\n",
    "        else:\n",
    "            context_parts.append(f\"Panel {i}: [No text]\")\n",
    "    context_dialogue = \"\\n\".join(context_parts)\n",
    "    \n",
    "    target_dialogue = sequence.get('target_text', '') or '[No text]'\n",
    "    target_dialogue = target_dialogue.strip()[:500] if target_dialogue.strip() else '[No text]'\n",
    "    \n",
    "    prompt = SCENE_DESCRIPTION_PROMPT.format(\n",
    "        context_dialogue=context_dialogue,\n",
    "        target_dialogue=target_dialogue\n",
    "    )\n",
    "    \n",
    "    image_parts = []\n",
    "    for panel in sequence['context']:\n",
    "        gcs_uri = delta_path_to_gcs_uri(panel['image_path'])\n",
    "        image_parts.append({\"file_data\": {\"file_uri\": gcs_uri, \"mime_type\": \"image/jpeg\"}})\n",
    "    target_gcs_uri = delta_path_to_gcs_uri(sequence['target']['image_path'])\n",
    "    image_parts.append({\"file_data\": {\"file_uri\": target_gcs_uri, \"mime_type\": \"image/jpeg\"}})\n",
    "    \n",
    "    request_body = {\n",
    "        \"contents\": [{\"role\": \"user\", \"parts\": image_parts + [{\"text\": prompt}]}],\n",
    "        \"generation_config\": {\"temperature\": 0.3, \"max_output_tokens\": 512, \"top_p\": 0.9}\n",
    "    }\n",
    "    \n",
    "    custom_id = f\"{seq_idx}_{sequence['comic_no']}_{sequence['story_idx']}_{sequence['target']['page_no']}_{sequence['target']['panel_no']}\"\n",
    "    return {\"custom_id\": custom_id, \"request\": request_body}\n",
    "\n",
    "print(\"Request builder ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating shards (249,576 sequences, 35,000 per shard)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249576/249576 [00:21<00:00, 11347.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 8 shards\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# C2: Create shards\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f\"Creating shards ({len(sequences):,} sequences, {SHARD_SIZE:,} per shard)...\")\n",
    "\n",
    "shard_idx = 0\n",
    "lines_in_shard = 0\n",
    "shard_paths = []\n",
    "\n",
    "current_shard_path = SHARDS_DIR / f\"shard_{shard_idx:04d}.jsonl\"\n",
    "shard_file = current_shard_path.open(\"w\", encoding=\"utf-8\")\n",
    "\n",
    "for seq_idx, seq in enumerate(tqdm(sequences)):\n",
    "    request = make_scene_request(seq_idx, seq)\n",
    "    shard_file.write(json.dumps(request) + \"\\n\")\n",
    "    lines_in_shard += 1\n",
    "    \n",
    "    if lines_in_shard >= SHARD_SIZE:\n",
    "        shard_file.close()\n",
    "        shard_paths.append(current_shard_path)\n",
    "        shard_idx += 1\n",
    "        lines_in_shard = 0\n",
    "        current_shard_path = SHARDS_DIR / f\"shard_{shard_idx:04d}.jsonl\"\n",
    "        shard_file = current_shard_path.open(\"w\", encoding=\"utf-8\")\n",
    "\n",
    "if lines_in_shard > 0:\n",
    "    shard_file.close()\n",
    "    shard_paths.append(current_shard_path)\n",
    "else:\n",
    "    shard_file.close()\n",
    "\n",
    "print(f\"Created {len(shard_paths)} shards\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART D: Upload & Submit\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 8/8 [00:05<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 8 shards\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# D1: Upload shards\n",
    "from tqdm import tqdm\n",
    "\n",
    "uploaded_uris = []\n",
    "for shard_path in tqdm(shard_paths, desc=\"Uploading\"):\n",
    "    gcs_path = f\"{GCS_BATCH_INPUT}/{shard_path.name}\"\n",
    "    blob = bucket_obj.blob(gcs_path)\n",
    "    blob.upload_from_filename(str(shard_path))\n",
    "    uploaded_uris.append(f\"gs://{BUCKET}/{gcs_path}\")\n",
    "\n",
    "print(f\"Uploaded {len(uploaded_uris)} shards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH COMMANDS - Run these in Cloud Shell:\n",
      "======================================================================\n",
      "\n",
      "# Batch 0\n",
      "gcloud ai models batch-predict \\\n",
      "  --model=gemini-2.5-flash-lite \\\n",
      "  --project=fluent-justice-478703-f8 \\\n",
      "  --region=us-central1 \\\n",
      "  --input-uri=gs://harshasekar-comics-data/batch_inputs/scene_descriptions/shard_0000.jsonl \\\n",
      "  --output-uri=gs://harshasekar-comics-data/scene_descriptions/outputs/job_0000/\n",
      "\n",
      "# Batch 1\n",
      "gcloud ai models batch-predict \\\n",
      "  --model=gemini-2.5-flash-lite \\\n",
      "  --project=fluent-justice-478703-f8 \\\n",
      "  --region=us-central1 \\\n",
      "  --input-uri=gs://harshasekar-comics-data/batch_inputs/scene_descriptions/shard_0001.jsonl \\\n",
      "  --output-uri=gs://harshasekar-comics-data/scene_descriptions/outputs/job_0001/\n",
      "\n",
      "# Batch 2\n",
      "gcloud ai models batch-predict \\\n",
      "  --model=gemini-2.5-flash-lite \\\n",
      "  --project=fluent-justice-478703-f8 \\\n",
      "  --region=us-central1 \\\n",
      "  --input-uri=gs://harshasekar-comics-data/batch_inputs/scene_descriptions/shard_0002.jsonl \\\n",
      "  --output-uri=gs://harshasekar-comics-data/scene_descriptions/outputs/job_0002/\n",
      "\n",
      "# Batch 3\n",
      "gcloud ai models batch-predict \\\n",
      "  --model=gemini-2.5-flash-lite \\\n",
      "  --project=fluent-justice-478703-f8 \\\n",
      "  --region=us-central1 \\\n",
      "  --input-uri=gs://harshasekar-comics-data/batch_inputs/scene_descriptions/shard_0003.jsonl \\\n",
      "  --output-uri=gs://harshasekar-comics-data/scene_descriptions/outputs/job_0003/\n",
      "\n",
      "# Batch 4\n",
      "gcloud ai models batch-predict \\\n",
      "  --model=gemini-2.5-flash-lite \\\n",
      "  --project=fluent-justice-478703-f8 \\\n",
      "  --region=us-central1 \\\n",
      "  --input-uri=gs://harshasekar-comics-data/batch_inputs/scene_descriptions/shard_0004.jsonl \\\n",
      "  --output-uri=gs://harshasekar-comics-data/scene_descriptions/outputs/job_0004/\n",
      "\n",
      "# Batch 5\n",
      "gcloud ai models batch-predict \\\n",
      "  --model=gemini-2.5-flash-lite \\\n",
      "  --project=fluent-justice-478703-f8 \\\n",
      "  --region=us-central1 \\\n",
      "  --input-uri=gs://harshasekar-comics-data/batch_inputs/scene_descriptions/shard_0005.jsonl \\\n",
      "  --output-uri=gs://harshasekar-comics-data/scene_descriptions/outputs/job_0005/\n",
      "\n",
      "# Batch 6\n",
      "gcloud ai models batch-predict \\\n",
      "  --model=gemini-2.5-flash-lite \\\n",
      "  --project=fluent-justice-478703-f8 \\\n",
      "  --region=us-central1 \\\n",
      "  --input-uri=gs://harshasekar-comics-data/batch_inputs/scene_descriptions/shard_0006.jsonl \\\n",
      "  --output-uri=gs://harshasekar-comics-data/scene_descriptions/outputs/job_0006/\n",
      "\n",
      "# Batch 7\n",
      "gcloud ai models batch-predict \\\n",
      "  --model=gemini-2.5-flash-lite \\\n",
      "  --project=fluent-justice-478703-f8 \\\n",
      "  --region=us-central1 \\\n",
      "  --input-uri=gs://harshasekar-comics-data/batch_inputs/scene_descriptions/shard_0007.jsonl \\\n",
      "  --output-uri=gs://harshasekar-comics-data/scene_descriptions/outputs/job_0007/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# D2: Generate submission commands\n",
    "print(\"BATCH COMMANDS - Run these in Cloud Shell:\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "for idx, uri in enumerate(uploaded_uris):\n",
    "    output_uri = f\"gs://{BUCKET}/{GCS_BATCH_OUTPUT}/job_{idx:04d}/\"\n",
    "    print(f\"# Batch {idx}\")\n",
    "    print(f\"gcloud ai models batch-predict \\\\\")\n",
    "    print(f\"  --model={MODEL} \\\\\")\n",
    "    print(f\"  --project={PROJECT_ID} \\\\\")\n",
    "    print(f\"  --region={LOCATION} \\\\\")\n",
    "    print(f\"  --input-uri={uri} \\\\\")\n",
    "    print(f\"  --output-uri={output_uri}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D3: Save script\n",
    "script_path = WORKDIR / \"submit_batches.sh\"\n",
    "with open(script_path, 'w') as f:\n",
    "    f.write(\"#!/bin/bash\\n\")\n",
    "    for idx, uri in enumerate(uploaded_uris):\n",
    "        output_uri = f\"gs://{BUCKET}/{GCS_BATCH_OUTPUT}/job_{idx:04d}/\"\n",
    "        f.write(f\"gcloud ai models batch-predict --model={MODEL} --project={PROJECT_ID} --region={LOCATION} --input-uri={uri} --output-uri={output_uri}\\n\")\n",
    "print(f\"Saved: {script_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART E: Monitor\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run in Cloud Shell:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'PROJECT_ID' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# E1: Check status command\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun in Cloud Shell:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgcloud ai batch-prediction-jobs list --project=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mPROJECT_ID\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m --region=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mLOCATION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PROJECT_ID' is not defined"
     ]
    }
   ],
   "source": [
    "# E1: Check status command\n",
    "print(\"Run in Cloud Shell:\")\n",
    "print(f\"gcloud ai batch-prediction-jobs list --project={PROJECT_ID} --region={LOCATION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 job folders\n"
     ]
    }
   ],
   "source": [
    "# E2: Check output files\n",
    "prefix = f\"{GCS_BATCH_OUTPUT}/\"\n",
    "blobs = list(bucket_obj.list_blobs(prefix=prefix))\n",
    "jobs = set()\n",
    "for blob in blobs:\n",
    "    parts = blob.name.split('/')\n",
    "    if len(parts) >= 3:\n",
    "        jobs.add(parts[2])\n",
    "print(f\"Found {len(jobs)} job folders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART F: Download Results\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 result files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing: 100%|██████████| 8/8 [00:16<00:00,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 249,571 results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# F1: Parse results\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "prefix = f\"{GCS_BATCH_OUTPUT}/\"\n",
    "result_blobs = [b for b in bucket_obj.list_blobs(prefix=prefix) if b.name.endswith('.jsonl')]\n",
    "print(f\"Found {len(result_blobs)} result files\")\n",
    "\n",
    "results = {}\n",
    "for blob in tqdm(result_blobs, desc=\"Parsing\"):\n",
    "    content = blob.download_as_text()\n",
    "    for line in content.strip().split('\\n'):\n",
    "        if not line:\n",
    "            continue\n",
    "        try:\n",
    "            data = json.loads(line)\n",
    "            custom_id = data.get('custom_id', '')\n",
    "            candidates = data.get('response', {}).get('candidates', [])\n",
    "            if candidates:\n",
    "                parts = candidates[0].get('content', {}).get('parts', [])\n",
    "                if parts:\n",
    "                    results[custom_id] = parts[0].get('text', '').strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "print(f\"Parsed {len(results):,} results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART G: Merge & Upload\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging: 100%|██████████| 249576/249576 [00:00<00:00, 387783.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched: 249,571/249,576 (100.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# G1: Merge\n",
    "from tqdm import tqdm\n",
    "\n",
    "matched = 0\n",
    "for seq_idx, seq in enumerate(tqdm(sequences, desc=\"Merging\")):\n",
    "    custom_id = f\"{seq_idx}_{seq['comic_no']}_{seq['story_idx']}_{seq['target']['page_no']}_{seq['target']['panel_no']}\"\n",
    "    if custom_id in results:\n",
    "        seq['scene_description'] = results[custom_id]\n",
    "        matched += 1\n",
    "    else:\n",
    "        seq['scene_description'] = seq.get('target_text', '')\n",
    "\n",
    "print(f\"Matched: {matched:,}/{len(sequences):,} ({100*matched/len(sequences):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved locally: train_sequences_with_descriptions.pkl\n",
      "Uploaded to: gs://harshasekar-comics-data/training_sequences/train_sequences_with_descriptions.pkl\n"
     ]
    }
   ],
   "source": [
    "# G2: Save & upload\n",
    "import pickle\n",
    "\n",
    "local_path = WORKDIR / \"train_sequences_with_descriptions.pkl\"\n",
    "with open(local_path, 'wb') as f:\n",
    "    pickle.dump(sequences, f)\n",
    "print(f\"Saved locally: {local_path}\")\n",
    "\n",
    "gcs_path = \"training_sequences/train_sequences_with_descriptions.pkl\"\n",
    "blob = bucket_obj.blob(gcs_path)\n",
    "blob.upload_from_filename(str(local_path))\n",
    "print(f\"Uploaded to: gs://{BUCKET}/{gcs_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample comparison:\n",
      "\n",
      "--- Sequence 0 ---\n",
      "OCR: I'VE BEEN WORKING ON IT FOR DAYS! I MUST GET A BREATH OF AIR AND CLEAR MY HEAD BEFORE I BEGIN MY TES...\n",
      "Scene: In Panel 6, the scene shifts to a close-up of a man with a prominent mustache, wearing a blue hat and overalls, and smoking a pipe. He is wiping sweat from his brow with a handkerchief, looking exhaus...\n",
      "\n",
      "--- Sequence 1 ---\n",
      "OCR: AH, I FEEL BETTER ALREADY! NOW FOR A BRISK WALK TO CALM MY JANGLED NERVES!...\n",
      "Scene: In Panel 6, a man with a large mustache and a pipe in his mouth, wearing overalls and a hat, steps out of a doorway onto a porch. He appears to be feeling refreshed, exclaiming, \"AH, I FEEL BETTER ALR...\n",
      "\n",
      "--- Sequence 2 ---\n",
      "OCR: And WEIGHTLESS WIGGINS, THUG AND PROFESSIONAL SECOND STORY MAN, WHO IS LURKING NEAR GIMMICK'S HOUSE....\n",
      "Scene: In Panel 6, the scene shifts outdoors to Gimmick's house, where a character named Weightless Wiggins, described as a thug and professional second-story man, is lurking. He observes Gimmick, who is wal...\n"
     ]
    }
   ],
   "source": [
    "# G3: Show comparison\n",
    "print(\"Sample comparison:\")\n",
    "for i in range(3):\n",
    "    seq = sequences[i]\n",
    "    print(f\"\\n--- Sequence {i} ---\")\n",
    "    print(f\"OCR: {seq['target_text'][:100]}...\")\n",
    "    print(f\"Scene: {seq.get('scene_description', 'N/A')[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Done!\n",
    "---\n",
    "\n",
    "**Output file:** `gs://harshasekar-comics-data/training_sequences/train_sequences_with_descriptions.pkl`\n",
    "\n",
    "**Next:** Update fine-tuning notebook to use `scene_description` instead of `target_text`"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m136",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m136"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
