{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Scene PREDICTIONS with Gemini Batch API\n",
    "\n",
    "---\n",
    "\n",
    "## ⚠️ KEY DIFFERENCE FROM PREVIOUS NOTEBOOK\n",
    "\n",
    "**OLD Notebook (08):** Gemini SAW Panel 6 → Described it (DESCRIPTION task)\n",
    "\n",
    "**THIS Notebook (09):** Gemini does NOT see Panel 6 → Predicts it (PREDICTION task)\n",
    "\n",
    "This aligns Gemini's task with LLaVA's task, fixing the training mismatch.\n",
    "\n",
    "---\n",
    "\n",
    "## How to Run This Notebook\n",
    "\n",
    "### Prerequisites\n",
    "1. Google Cloud Project with Vertex AI API enabled\n",
    "2. GCS Bucket with data uploaded:\n",
    "   - `gs://harshasekar-comics-data/training_sequences/train_sequences.pkl`\n",
    "   - `gs://harshasekar-comics-data/raw_panel_images/`\n",
    "3. Authentication configured\n",
    "\n",
    "### Steps\n",
    "\n",
    "| Step | Action | Time |\n",
    "|------|--------|------|\n",
    "| 1 | Run Part A (Setup) | 1 min |\n",
    "| 2 | Run Part B (Test 5 examples) | 2 min |\n",
    "| 3 | STOP - Verify predictions look reasonable | - |\n",
    "| 4 | If approved, run Part C (Build shards) | 10 min |\n",
    "| 5 | Run Part D (Upload & submit) | 5 min |\n",
    "| 6 | Run commands in Cloud Shell | 20-24 hrs |\n",
    "| 7 | Run Part E (Monitor) | - |\n",
    "| 8 | Run Part F (Download results) | 10 min |\n",
    "| 9 | Run Part G (Merge & upload) | 5 min |\n",
    "\n",
    "### Cost\n",
    "- Test job: ~$0.01\n",
    "- Full batch: ~$20-25 (slightly less than before - no Panel 6 image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART A: Configuration\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready\n"
     ]
    }
   ],
   "source": [
    "# A1: Install dependencies (Colab)\n",
    "# !pip install -q google-cloud-storage google-cloud-aiplatform tqdm\n",
    "print(\"Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready\n"
     ]
    }
   ],
   "source": [
    "# A2: Authenticate (Colab)\n",
    "# from google.colab import auth\n",
    "# auth.authenticate_user()\n",
    "print(\"Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project: fluent-justice-478703-f8\n",
      "Bucket: harshasekar-comics-data\n",
      "Model: gemini-2.5-flash-lite\n",
      "\n",
      "⚠️ This notebook generates PREDICTIONS (Gemini won't see Panel 6)\n"
     ]
    }
   ],
   "source": [
    "# A3: Configuration\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ID = \"fluent-justice-478703-f8\"\n",
    "LOCATION = \"us-central1\"\n",
    "BUCKET = \"harshasekar-comics-data\"\n",
    "\n",
    "GCS_SEQUENCES_PATH = \"training_sequences/train_sequences.pkl\"\n",
    "GCS_IMAGES_PREFIX = \"raw_panel_images\"\n",
    "\n",
    "# NEW: Different output paths to avoid overwriting old data\n",
    "GCS_BATCH_INPUT = \"batch_inputs/scene_predictions\"  # CHANGED\n",
    "GCS_BATCH_OUTPUT = \"scene_predictions/outputs\"      # CHANGED\n",
    "\n",
    "SHARD_SIZE = 35000\n",
    "MODEL = \"gemini-2.5-flash-lite\"\n",
    "\n",
    "WORKDIR = Path(\".\")\n",
    "SHARDS_DIR = WORKDIR / \"scene_pred_shards\"  # CHANGED\n",
    "SHARDS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Project: {PROJECT_ID}\")\n",
    "print(f\"Bucket: {BUCKET}\")\n",
    "print(f\"Model: {MODEL}\")\n",
    "print(f\"\\n⚠️ This notebook generates PREDICTIONS (Gemini won't see Panel 6)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from gs://harshasekar-comics-data/training_sequences/train_sequences.pkl\n",
      "Loaded 249,576 sequences\n"
     ]
    }
   ],
   "source": [
    "# A4: Load sequences\n",
    "import pickle\n",
    "from google.cloud import storage\n",
    "\n",
    "print(f\"Loading from gs://{BUCKET}/{GCS_SEQUENCES_PATH}\")\n",
    "\n",
    "client = storage.Client(project=PROJECT_ID)\n",
    "bucket_obj = client.bucket(BUCKET)\n",
    "blob = bucket_obj.blob(GCS_SEQUENCES_PATH)\n",
    "\n",
    "pkl_bytes = blob.download_as_bytes()\n",
    "sequences = pickle.loads(pkl_bytes)\n",
    "\n",
    "print(f\"Loaded {len(sequences):,} sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta: /scratch/bftl/hsekar/comics_project/data/images/0/2_0.jpg\n",
      "GCS:   gs://harshasekar-comics-data/raw_panel_images/0/2_0.jpg\n"
     ]
    }
   ],
   "source": [
    "# A5: Path conversion helper\n",
    "def delta_path_to_gcs_uri(delta_path: str) -> str:\n",
    "    path = Path(delta_path)\n",
    "    comic_no = path.parent.name\n",
    "    filename = path.name\n",
    "    return f\"gs://{BUCKET}/{GCS_IMAGES_PREFIX}/{comic_no}/{filename}\"\n",
    "\n",
    "# Test\n",
    "test_path = sequences[0]['context'][0]['image_path']\n",
    "print(f\"Delta: {test_path}\")\n",
    "print(f\"GCS:   {delta_path_to_gcs_uri(test_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt template (PREDICTION - no Panel 6):\n",
      "============================================================\n",
      "You are looking at 5 consecutive panels from a comic book.\n",
      "\n",
      "Here is the text from each panel:\n",
      "{context_dialogue}\n",
      "\n",
      "Based on the story so far, predict what happens in the next panel (Panel 6).\n",
      "Describe the likely scene, characters, actions, and any dialogue.\n",
      "\n",
      "Write your response as a single flowing paragraph. Do not use bullet points, \n",
      "numbered lists, bold text, asterisks, or any markdown formatting. \n",
      "Weave the dialogue naturally into your description.\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "✅ This prompt is IDENTICAL to what LLaVA will see during training and inference.\n"
     ]
    }
   ],
   "source": [
    "# A6: Prompt template - IDENTICAL TO LLAVA PROMPT\n",
    "#\n",
    "# ╔═══════════════════════════════════════════════════════════════════════════╗\n",
    "# ║  KEY CHANGE: This prompt is now IDENTICAL to what LLaVA sees!             ║\n",
    "# ║  - Only 5 panels (no Panel 6)                                             ║\n",
    "# ║  - Task is to PREDICT, not DESCRIBE                                       ║\n",
    "# ║  - No target_dialogue (we don't know what's in Panel 6)                   ║\n",
    "# ╚═══════════════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "SCENE_PREDICTION_PROMPT = '''You are looking at 5 consecutive panels from a comic book.\n",
    "\n",
    "Here is the text from each panel:\n",
    "{context_dialogue}\n",
    "\n",
    "Based on the story so far, predict what happens in the next panel (Panel 6).\n",
    "Describe the likely scene, characters, actions, and any dialogue.\n",
    "\n",
    "Write your response as a single flowing paragraph. Do not use bullet points, \n",
    "numbered lists, bold text, asterisks, or any markdown formatting. \n",
    "Weave the dialogue naturally into your description.\n",
    "\n",
    "'''\n",
    "\n",
    "print(\"Prompt template (PREDICTION - no Panel 6):\")\n",
    "print(\"=\"*60)\n",
    "print(SCENE_PREDICTION_PROMPT)\n",
    "print(\"=\"*60)\n",
    "print(\"\\n✅ This prompt is IDENTICAL to what LLaVA will see during training and inference.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART B: Test Job (5 Examples)\n",
    "---\n",
    "\n",
    "**Run this before the full batch to verify output quality!**\n",
    "\n",
    "The predictions should be:\n",
    "- Reasonable guesses based on story context\n",
    "- NOT specific details that can only be known by seeing Panel 6\n",
    "- Similar in style to what we want LLaVA to produce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready: gemini-2.5-flash-lite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/vertexai/generative_models/_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n"
     ]
    }
   ],
   "source": [
    "# B1: Setup Gemini\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "import time\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "model = GenerativeModel(MODEL)\n",
    "print(f\"Model ready: {MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 5 sequences: [167621, 29184, 6556, 194393, 72097]\n",
      "\n",
      "[1/5] Comic 992, Story 0...\n",
      "   OK\n",
      "[2/5] Comic 191, Story 3...\n",
      "   OK\n",
      "[3/5] Comic 40, Story 0...\n",
      "   OK\n",
      "[4/5] Comic 1149, Story 5...\n",
      "   OK\n",
      "[5/5] Comic 469, Story 0...\n",
      "   OK\n",
      "\n",
      "Done: 5/5 successful\n"
     ]
    }
   ],
   "source": [
    "# B2: Run test - ONLY 5 PANELS, NO PANEL 6!\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "test_indices = random.sample(range(len(sequences)), 5)\n",
    "test_sequences = [sequences[i] for i in test_indices]\n",
    "\n",
    "print(f\"Testing {len(test_sequences)} sequences: {test_indices}\\n\")\n",
    "\n",
    "test_results = []\n",
    "\n",
    "for i, seq in enumerate(test_sequences):\n",
    "    print(f\"[{i+1}/5] Comic {seq['comic_no']}, Story {seq['story_idx']}...\")\n",
    "    \n",
    "    # Build context dialogue - ONLY PANELS 1-5\n",
    "    context_texts = seq.get('context_texts', [])\n",
    "    context_parts = []\n",
    "    for j, text in enumerate(context_texts, 1):\n",
    "        if text and text.strip():\n",
    "            context_parts.append(f\"Panel {j}: {text.strip()[:400]}\")\n",
    "        else:\n",
    "            context_parts.append(f\"Panel {j}: [No text]\")\n",
    "    context_dialogue = \"\\n\".join(context_parts)\n",
    "    \n",
    "    # NO target_dialogue - we're predicting!\n",
    "    \n",
    "    # Fill prompt - only context_dialogue now\n",
    "    prompt = SCENE_PREDICTION_PROMPT.format(\n",
    "        context_dialogue=context_dialogue\n",
    "    )\n",
    "    \n",
    "    # Build image parts - ONLY 5 CONTEXT PANELS, NOT PANEL 6!\n",
    "    image_parts = []\n",
    "    for panel in seq['context']:\n",
    "        gcs_uri = delta_path_to_gcs_uri(panel['image_path'])\n",
    "        image_parts.append(Part.from_uri(gcs_uri, mime_type=\"image/jpeg\"))\n",
    "    \n",
    "    # ❌ REMOVED: target panel image - we don't send Panel 6!\n",
    "    \n",
    "    # Call Gemini\n",
    "    try:\n",
    "        response = model.generate_content(\n",
    "            image_parts + [prompt],\n",
    "            generation_config={\"temperature\": 0.3, \"top_p\": 0.9}\n",
    "        )\n",
    "        scene_prediction = response.text.strip()\n",
    "        test_results.append({\n",
    "            'index': test_indices[i],\n",
    "            'comic_no': seq['comic_no'],\n",
    "            'story_idx': seq['story_idx'],\n",
    "            'actual_target_text': seq.get('target_text', '[No text]'),  # For comparison\n",
    "            'scene_prediction': scene_prediction,\n",
    "            'status': 'success'\n",
    "        })\n",
    "        print(f\"   OK\")\n",
    "    except Exception as e:\n",
    "        test_results.append({\n",
    "            'index': test_indices[i],\n",
    "            'comic_no': seq['comic_no'],\n",
    "            'story_idx': seq['story_idx'],\n",
    "            'actual_target_text': seq.get('target_text', '[No text]'),\n",
    "            'error': str(e),\n",
    "            'status': 'failed'\n",
    "        })\n",
    "        print(f\"   ERROR: {e}\")\n",
    "    \n",
    "    time.sleep(1)\n",
    "\n",
    "print(f\"\\nDone: {sum(1 for r in test_results if r['status']=='success')}/5 successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEST RESULTS - PREDICTION STYLE (Gemini did NOT see Panel 6)\n",
      "======================================================================\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "TEST 1/5 | Index: 167621 | Comic: 992, Story: 0\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "\n",
      "ACTUAL PANEL 6 TEXT (for reference - Gemini did NOT see this):\n",
      "  THE DOLL MAN GOES INTO ACTION... HEADS UP!! WHAT TH.. !!?\n",
      "\n",
      "GEMINI PREDICTION (what Gemini thinks happens next):\n",
      "  The lights have just come back on after being abruptly turned off, and the scene is now one of chaos and robbery. The man holding the gun, likely the leader of the robbers, is issuing orders to his accomplices, telling them to \"take everything that ain't nailed down.\" The other men present, who were likely gathered for some sort of event or meeting before the lights went out, are now in a state of panic and fear, with some looking around in confusion and others reacting with alarm to the armed robbery. It's possible that Rocky Perrone, mentioned in the first panel, might be involved in this robbery or is about to make his presence known in response to the unfolding events.\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "TEST 2/5 | Index: 29184 | Comic: 191, Story: 3\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "\n",
      "ACTUAL PANEL 6 TEXT (for reference - Gemini did NOT see this):\n",
      "  BUT A FEW BLOCKS AWAY, AMAY APPEARS AGAIN, AND HAILS A TAXI- TO THE AIRPORT- AND HURRY!\n",
      "\n",
      "GEMINI PREDICTION (what Gemini thinks happens next):\n",
      "  The man in the brown suit, who was just about to confront the two witnesses, is now looking around in confusion, exclaiming \"Say! Wait a minute! The guys vanished!\" The two witnesses, who were previously being threatened, are nowhere to be seen, having apparently escaped during the commotion. The man in the red suit, who was heading towards the dam, is likely still on his way, unaware of the witnesses' disappearance. The next panel will probably show the man in the brown suit searching for the vanished witnesses, perhaps calling out to them or looking for clues, while the man in the red suit continues his urgent mission to the dam.\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "TEST 3/5 | Index: 6556 | Comic: 40, Story: 0\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "\n",
      "ACTUAL PANEL 6 TEXT (for reference - Gemini did NOT see this):\n",
      "  YOU MEAN THERE'S NO SIGNS? NO, WHOEVER THE RUSTLER IS, HE'S PICKIN' ONLY THE BEST STEERS AND RUNNIN' 'EM OFF ONE AT A TIME!\n",
      "\n",
      "GEMINI PREDICTION (what Gemini thinks happens next):\n",
      "  In the next panel, Red and Punchy will likely continue their investigation into the peculiar rustling. Red, having just declared the thief \"mighty clever,\" might be examining some evidence left behind, perhaps a footprint or a dropped item, while Punchy, ever eager, could be looking around for any signs of movement. The sheriff might join them, offering further details about the rustling, or perhaps they'll spot the elusive Pecos Pete in the distance, setting up a chase. Red might say something like, \"Clever indeed, but not clever enough to fool us!\" and Punchy could exclaim, \"Let's get him, Red!\" as they prepare to follow the trail.\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "TEST 4/5 | Index: 194393 | Comic: 1149, Story: 5\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "\n",
      "ACTUAL PANEL 6 TEXT (for reference - Gemini did NOT see this):\n",
      "  NO QUESTIONS, MISTER! I CANNOT TELL YOU WHY, BUT I MUST HAVE IT BACK! IT IS LIFE OR DEATH - I WILL PAY YOU TWICE WHAT YOU GAVE ME FOR IT! HMM- WELL, OKAY! IF YOU WANT IT THAT BADLY! ON GO MO WO AL TH\n",
      "\n",
      "GEMINI PREDICTION (what Gemini thinks happens next):\n",
      "  The seller, looking desperate and perhaps a bit crazed, will likely explain that the hand is not just a souvenir but a cursed object that brings misfortune to anyone who possesses it, and that he needs it back to break the curse on himself or someone he cares about. Sam, initially dismissive, will start to feel a sense of unease, especially with Anne still missing, and will likely demand to know the truth about the hand's curse. The seller might reveal that the hand's curse causes bad luck and misfortune, and that he is terrified of what might happen if Sam keeps it, perhaps hinting that Anne's disappearance is already a consequence of the hand's influence.\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "TEST 5/5 | Index: 72097 | Comic: 469, Story: 0\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "\n",
      "ACTUAL PANEL 6 TEXT (for reference - Gemini did NOT see this):\n",
      "  BUT JEAN DOES NOT APPEAR! THEY ENTER--AND... YOU'RE MISTAKEN! YOUR FRIEND DIDN'T COME TO THIS STORE! YOU'RE LYING... SHE MUST BE HERE! UNLESS YOU LEAVE AT ONCE, I SHALL CALL THE POLICE!\n",
      "\n",
      "GEMINI PREDICTION (what Gemini thinks happens next):\n",
      "  In the next panel, the two masked heroes, Bob and Tim, will likely investigate the shop where Jean was last seen. They will probably enter the store, perhaps still in their costumes, and look for Jean or any signs of trouble. One of them might say something like, \"This is too strange, Bob. We have to find out what's going on,\" while the other replies, \"You're right, Tim. Let's see if we can find Jean or that saleslady.\" They might then confront the saleslady or another employee, demanding to know where Jean went and why she was arguing about the dress. The saleslady might try to dismiss them or give a vague explanation, but the heroes, sensing something is amiss, will press for the truth, possibly leading to a confrontation or the discovery of a hidden plot.\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────\n",
      "END OF TEST RESULTS\n",
      "\n",
      "⚠️ VERIFY: Predictions should be reasonable guesses, NOT specific details.\n",
      "   If predictions contain impossible-to-know details, something is wrong.\n"
     ]
    }
   ],
   "source": [
    "# B3: Display results - VERIFY THESE LOOK LIKE REASONABLE PREDICTIONS\n",
    "print(\"=\"*70)\n",
    "print(\"TEST RESULTS - PREDICTION STYLE (Gemini did NOT see Panel 6)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, result in enumerate(test_results):\n",
    "    print(f\"\\n{'─'*70}\")\n",
    "    print(f\"TEST {i+1}/5 | Index: {result['index']} | Comic: {result['comic_no']}, Story: {result['story_idx']}\")\n",
    "    print(f\"{'─'*70}\")\n",
    "    \n",
    "    print(f\"\\nACTUAL PANEL 6 TEXT (for reference - Gemini did NOT see this):\")\n",
    "    print(f\"  {result['actual_target_text'][:200]}...\" if len(result.get('actual_target_text', '')) > 200 else f\"  {result.get('actual_target_text', '[No text]')}\")\n",
    "    \n",
    "    if result['status'] == 'success':\n",
    "        print(f\"\\nGEMINI PREDICTION (what Gemini thinks happens next):\")\n",
    "        print(f\"  {result['scene_prediction']}\")\n",
    "    else:\n",
    "        print(f\"\\nERROR: {result.get('error')}\")\n",
    "\n",
    "print(f\"\\n{'─'*70}\")\n",
    "print(\"END OF TEST RESULTS\")\n",
    "print(\"\\n⚠️ VERIFY: Predictions should be reasonable guesses, NOT specific details.\")\n",
    "print(\"   If predictions contain impossible-to-know details, something is wrong.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to test_prediction_results.json\n"
     ]
    }
   ],
   "source": [
    "# B4: Save test results\n",
    "import json\n",
    "with open(WORKDIR / \"test_prediction_results.json\", 'w') as f:\n",
    "    json.dump(test_results, f, indent=2, default=str)\n",
    "print(\"Saved to test_prediction_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# STOP - Verify predictions look reasonable before continuing!\n",
    "---\n",
    "\n",
    "### What to Check:\n",
    "\n",
    "✅ **Good predictions:** \"The characters likely continue their escape. There may be dialogue about their next move...\"\n",
    "\n",
    "❌ **Bad predictions:** \"John says 'The code is 7432' while standing next to the BLUE door...\" (too specific)\n",
    "\n",
    "If predictions look reasonable, continue to Part C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART C: Build JSONL Shards\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request builder ready\n",
      "⚠️ Each request contains ONLY 5 images (no Panel 6)\n"
     ]
    }
   ],
   "source": [
    "# C1: Request builder - ONLY 5 PANELS, NO PANEL 6!\n",
    "import json\n",
    "\n",
    "def make_prediction_request(seq_idx, sequence):\n",
    "    \"\"\"Create a batch request with ONLY 5 context panels (no Panel 6).\"\"\"\n",
    "    \n",
    "    # Build context dialogue - ONLY PANELS 1-5\n",
    "    context_texts = sequence.get('context_texts', [])\n",
    "    context_parts = []\n",
    "    for i, text in enumerate(context_texts, 1):\n",
    "        if text and text.strip():\n",
    "            context_parts.append(f\"Panel {i}: {text.strip()[:400]}\")\n",
    "        else:\n",
    "            context_parts.append(f\"Panel {i}: [No text]\")\n",
    "    context_dialogue = \"\\n\".join(context_parts)\n",
    "    \n",
    "    # NO target_dialogue - we're predicting!\n",
    "    \n",
    "    # Fill prompt - only context_dialogue\n",
    "    prompt = SCENE_PREDICTION_PROMPT.format(\n",
    "        context_dialogue=context_dialogue\n",
    "    )\n",
    "    \n",
    "    # Build image parts - ONLY 5 CONTEXT PANELS!\n",
    "    image_parts = []\n",
    "    for panel in sequence['context']:\n",
    "        gcs_uri = delta_path_to_gcs_uri(panel['image_path'])\n",
    "        image_parts.append({\"file_data\": {\"file_uri\": gcs_uri, \"mime_type\": \"image/jpeg\"}})\n",
    "    \n",
    "    # ❌ REMOVED: target panel image\n",
    "    \n",
    "    request_body = {\n",
    "        \"contents\": [{\"role\": \"user\", \"parts\": image_parts + [{\"text\": prompt}]}],\n",
    "        \"generation_config\": {\"temperature\": 0.3, \"max_output_tokens\": 512, \"top_p\": 0.9}\n",
    "    }\n",
    "    \n",
    "    custom_id = f\"{seq_idx}_{sequence['comic_no']}_{sequence['story_idx']}_{sequence['target']['page_no']}_{sequence['target']['panel_no']}\"\n",
    "    return {\"custom_id\": custom_id, \"request\": request_body}\n",
    "\n",
    "print(\"Request builder ready\")\n",
    "print(\"⚠️ Each request contains ONLY 5 images (no Panel 6)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating shards (249,576 sequences, 35,000 per shard)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249576/249576 [00:21<00:00, 11770.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 8 shards\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# C2: Create shards\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f\"Creating shards ({len(sequences):,} sequences, {SHARD_SIZE:,} per shard)...\")\n",
    "\n",
    "shard_idx = 0\n",
    "lines_in_shard = 0\n",
    "shard_paths = []\n",
    "\n",
    "current_shard_path = SHARDS_DIR / f\"shard_{shard_idx:04d}.jsonl\"\n",
    "shard_file = current_shard_path.open(\"w\", encoding=\"utf-8\")\n",
    "\n",
    "for seq_idx, seq in enumerate(tqdm(sequences)):\n",
    "    request = make_prediction_request(seq_idx, seq)  # CHANGED function name\n",
    "    shard_file.write(json.dumps(request) + \"\\n\")\n",
    "    lines_in_shard += 1\n",
    "    \n",
    "    if lines_in_shard >= SHARD_SIZE:\n",
    "        shard_file.close()\n",
    "        shard_paths.append(current_shard_path)\n",
    "        shard_idx += 1\n",
    "        lines_in_shard = 0\n",
    "        current_shard_path = SHARDS_DIR / f\"shard_{shard_idx:04d}.jsonl\"\n",
    "        shard_file = current_shard_path.open(\"w\", encoding=\"utf-8\")\n",
    "\n",
    "if lines_in_shard > 0:\n",
    "    shard_file.close()\n",
    "    shard_paths.append(current_shard_path)\n",
    "else:\n",
    "    shard_file.close()\n",
    "\n",
    "print(f\"Created {len(shard_paths)} shards\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART D: Upload & Submit\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████| 8/8 [00:05<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 8 shards\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# D1: Upload shards\n",
    "from tqdm import tqdm\n",
    "\n",
    "uploaded_uris = []\n",
    "for shard_path in tqdm(shard_paths, desc=\"Uploading\"):\n",
    "    gcs_path = f\"{GCS_BATCH_INPUT}/{shard_path.name}\"\n",
    "    blob = bucket_obj.blob(gcs_path)\n",
    "    blob.upload_from_filename(str(shard_path))\n",
    "    uploaded_uris.append(f\"gs://{BUCKET}/{gcs_path}\")\n",
    "\n",
    "print(f\"Uploaded {len(uploaded_uris)} shards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "RUN THESE COMMANDS IN GOOGLE CLOUD SHELL\n",
      "======================================================================\n",
      "\n",
      "# Shard 0\n",
      "curl -X POST \\\n",
      "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
      "  -H \"Content-Type: application/json\" \\\n",
      "  https://us-central1-aiplatform.googleapis.com/v1/projects/fluent-justice-478703-f8/locations/us-central1/batchPredictionJobs \\\n",
      "  -d '{\n",
      "    \"displayName\": \"scene-predictions-shard-0000\",\n",
      "    \"model\": \"publishers/google/models/gemini-2.5-flash-lite\",\n",
      "    \"inputConfig\": {\n",
      "      \"instancesFormat\": \"jsonl\",\n",
      "      \"gcsSource\": {\n",
      "        \"uris\": [\"gs://harshasekar-comics-data/batch_inputs/scene_predictions/shard_0000.jsonl\"]\n",
      "      }\n",
      "    },\n",
      "    \"outputConfig\": {\n",
      "      \"predictionsFormat\": \"jsonl\",\n",
      "      \"gcsDestination\": {\n",
      "        \"outputUriPrefix\": \"gs://harshasekar-comics-data/scene_predictions/outputs/shard_0000/\"\n",
      "      }\n",
      "    }\n",
      "  }'\n",
      "\n",
      "sleep 2\n",
      "\n",
      "# Shard 1\n",
      "curl -X POST \\\n",
      "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
      "  -H \"Content-Type: application/json\" \\\n",
      "  https://us-central1-aiplatform.googleapis.com/v1/projects/fluent-justice-478703-f8/locations/us-central1/batchPredictionJobs \\\n",
      "  -d '{\n",
      "    \"displayName\": \"scene-predictions-shard-0001\",\n",
      "    \"model\": \"publishers/google/models/gemini-2.5-flash-lite\",\n",
      "    \"inputConfig\": {\n",
      "      \"instancesFormat\": \"jsonl\",\n",
      "      \"gcsSource\": {\n",
      "        \"uris\": [\"gs://harshasekar-comics-data/batch_inputs/scene_predictions/shard_0001.jsonl\"]\n",
      "      }\n",
      "    },\n",
      "    \"outputConfig\": {\n",
      "      \"predictionsFormat\": \"jsonl\",\n",
      "      \"gcsDestination\": {\n",
      "        \"outputUriPrefix\": \"gs://harshasekar-comics-data/scene_predictions/outputs/shard_0001/\"\n",
      "      }\n",
      "    }\n",
      "  }'\n",
      "\n",
      "sleep 2\n",
      "\n",
      "# Shard 2\n",
      "curl -X POST \\\n",
      "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
      "  -H \"Content-Type: application/json\" \\\n",
      "  https://us-central1-aiplatform.googleapis.com/v1/projects/fluent-justice-478703-f8/locations/us-central1/batchPredictionJobs \\\n",
      "  -d '{\n",
      "    \"displayName\": \"scene-predictions-shard-0002\",\n",
      "    \"model\": \"publishers/google/models/gemini-2.5-flash-lite\",\n",
      "    \"inputConfig\": {\n",
      "      \"instancesFormat\": \"jsonl\",\n",
      "      \"gcsSource\": {\n",
      "        \"uris\": [\"gs://harshasekar-comics-data/batch_inputs/scene_predictions/shard_0002.jsonl\"]\n",
      "      }\n",
      "    },\n",
      "    \"outputConfig\": {\n",
      "      \"predictionsFormat\": \"jsonl\",\n",
      "      \"gcsDestination\": {\n",
      "        \"outputUriPrefix\": \"gs://harshasekar-comics-data/scene_predictions/outputs/shard_0002/\"\n",
      "      }\n",
      "    }\n",
      "  }'\n",
      "\n",
      "sleep 2\n",
      "\n",
      "# Shard 3\n",
      "curl -X POST \\\n",
      "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
      "  -H \"Content-Type: application/json\" \\\n",
      "  https://us-central1-aiplatform.googleapis.com/v1/projects/fluent-justice-478703-f8/locations/us-central1/batchPredictionJobs \\\n",
      "  -d '{\n",
      "    \"displayName\": \"scene-predictions-shard-0003\",\n",
      "    \"model\": \"publishers/google/models/gemini-2.5-flash-lite\",\n",
      "    \"inputConfig\": {\n",
      "      \"instancesFormat\": \"jsonl\",\n",
      "      \"gcsSource\": {\n",
      "        \"uris\": [\"gs://harshasekar-comics-data/batch_inputs/scene_predictions/shard_0003.jsonl\"]\n",
      "      }\n",
      "    },\n",
      "    \"outputConfig\": {\n",
      "      \"predictionsFormat\": \"jsonl\",\n",
      "      \"gcsDestination\": {\n",
      "        \"outputUriPrefix\": \"gs://harshasekar-comics-data/scene_predictions/outputs/shard_0003/\"\n",
      "      }\n",
      "    }\n",
      "  }'\n",
      "\n",
      "sleep 2\n",
      "\n",
      "# Shard 4\n",
      "curl -X POST \\\n",
      "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
      "  -H \"Content-Type: application/json\" \\\n",
      "  https://us-central1-aiplatform.googleapis.com/v1/projects/fluent-justice-478703-f8/locations/us-central1/batchPredictionJobs \\\n",
      "  -d '{\n",
      "    \"displayName\": \"scene-predictions-shard-0004\",\n",
      "    \"model\": \"publishers/google/models/gemini-2.5-flash-lite\",\n",
      "    \"inputConfig\": {\n",
      "      \"instancesFormat\": \"jsonl\",\n",
      "      \"gcsSource\": {\n",
      "        \"uris\": [\"gs://harshasekar-comics-data/batch_inputs/scene_predictions/shard_0004.jsonl\"]\n",
      "      }\n",
      "    },\n",
      "    \"outputConfig\": {\n",
      "      \"predictionsFormat\": \"jsonl\",\n",
      "      \"gcsDestination\": {\n",
      "        \"outputUriPrefix\": \"gs://harshasekar-comics-data/scene_predictions/outputs/shard_0004/\"\n",
      "      }\n",
      "    }\n",
      "  }'\n",
      "\n",
      "sleep 2\n",
      "\n",
      "# Shard 5\n",
      "curl -X POST \\\n",
      "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
      "  -H \"Content-Type: application/json\" \\\n",
      "  https://us-central1-aiplatform.googleapis.com/v1/projects/fluent-justice-478703-f8/locations/us-central1/batchPredictionJobs \\\n",
      "  -d '{\n",
      "    \"displayName\": \"scene-predictions-shard-0005\",\n",
      "    \"model\": \"publishers/google/models/gemini-2.5-flash-lite\",\n",
      "    \"inputConfig\": {\n",
      "      \"instancesFormat\": \"jsonl\",\n",
      "      \"gcsSource\": {\n",
      "        \"uris\": [\"gs://harshasekar-comics-data/batch_inputs/scene_predictions/shard_0005.jsonl\"]\n",
      "      }\n",
      "    },\n",
      "    \"outputConfig\": {\n",
      "      \"predictionsFormat\": \"jsonl\",\n",
      "      \"gcsDestination\": {\n",
      "        \"outputUriPrefix\": \"gs://harshasekar-comics-data/scene_predictions/outputs/shard_0005/\"\n",
      "      }\n",
      "    }\n",
      "  }'\n",
      "\n",
      "sleep 2\n",
      "\n",
      "# Shard 6\n",
      "curl -X POST \\\n",
      "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
      "  -H \"Content-Type: application/json\" \\\n",
      "  https://us-central1-aiplatform.googleapis.com/v1/projects/fluent-justice-478703-f8/locations/us-central1/batchPredictionJobs \\\n",
      "  -d '{\n",
      "    \"displayName\": \"scene-predictions-shard-0006\",\n",
      "    \"model\": \"publishers/google/models/gemini-2.5-flash-lite\",\n",
      "    \"inputConfig\": {\n",
      "      \"instancesFormat\": \"jsonl\",\n",
      "      \"gcsSource\": {\n",
      "        \"uris\": [\"gs://harshasekar-comics-data/batch_inputs/scene_predictions/shard_0006.jsonl\"]\n",
      "      }\n",
      "    },\n",
      "    \"outputConfig\": {\n",
      "      \"predictionsFormat\": \"jsonl\",\n",
      "      \"gcsDestination\": {\n",
      "        \"outputUriPrefix\": \"gs://harshasekar-comics-data/scene_predictions/outputs/shard_0006/\"\n",
      "      }\n",
      "    }\n",
      "  }'\n",
      "\n",
      "sleep 2\n",
      "\n",
      "# Shard 7\n",
      "curl -X POST \\\n",
      "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
      "  -H \"Content-Type: application/json\" \\\n",
      "  https://us-central1-aiplatform.googleapis.com/v1/projects/fluent-justice-478703-f8/locations/us-central1/batchPredictionJobs \\\n",
      "  -d '{\n",
      "    \"displayName\": \"scene-predictions-shard-0007\",\n",
      "    \"model\": \"publishers/google/models/gemini-2.5-flash-lite\",\n",
      "    \"inputConfig\": {\n",
      "      \"instancesFormat\": \"jsonl\",\n",
      "      \"gcsSource\": {\n",
      "        \"uris\": [\"gs://harshasekar-comics-data/batch_inputs/scene_predictions/shard_0007.jsonl\"]\n",
      "      }\n",
      "    },\n",
      "    \"outputConfig\": {\n",
      "      \"predictionsFormat\": \"jsonl\",\n",
      "      \"gcsDestination\": {\n",
      "        \"outputUriPrefix\": \"gs://harshasekar-comics-data/scene_predictions/outputs/shard_0007/\"\n",
      "      }\n",
      "    }\n",
      "  }'\n",
      "\n",
      "sleep 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# D2: Generate Cloud Shell commands\n",
    "print(\"=\" * 70)\n",
    "print(\"RUN THESE COMMANDS IN GOOGLE CLOUD SHELL\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "for i, uri in enumerate(uploaded_uris):\n",
    "    output_uri = f\"gs://{BUCKET}/{GCS_BATCH_OUTPUT}/shard_{i:04d}/\"\n",
    "    print(f\"# Shard {i}\")\n",
    "    print(f\"\"\"curl -X POST \\\\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\\\n",
    "  -H \"Content-Type: application/json\" \\\\\n",
    "  https://{LOCATION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{LOCATION}/batchPredictionJobs \\\\\n",
    "  -d '{{\n",
    "    \"displayName\": \"scene-predictions-shard-{i:04d}\",\n",
    "    \"model\": \"publishers/google/models/{MODEL}\",\n",
    "    \"inputConfig\": {{\n",
    "      \"instancesFormat\": \"jsonl\",\n",
    "      \"gcsSource\": {{\n",
    "        \"uris\": [\"{uri}\"]\n",
    "      }}\n",
    "    }},\n",
    "    \"outputConfig\": {{\n",
    "      \"predictionsFormat\": \"jsonl\",\n",
    "      \"gcsDestination\": {{\n",
    "        \"outputUriPrefix\": \"{output_uri}\"\n",
    "      }}\n",
    "    }}\n",
    "  }}'\"\"\")\n",
    "    print()\n",
    "    print(\"sleep 2\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART E: Monitor Jobs\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E1: Check status command\n",
    "print(\"Run in Cloud Shell:\")\n",
    "print(f\"gcloud ai batch-prediction-jobs list --project={PROJECT_ID} --region={LOCATION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E2: Check output files\n",
    "prefix = f\"{GCS_BATCH_OUTPUT}/\"\n",
    "blobs = list(bucket_obj.list_blobs(prefix=prefix))\n",
    "jobs = set()\n",
    "for blob in blobs:\n",
    "    parts = blob.name.split('/')\n",
    "    if len(parts) >= 3:\n",
    "        jobs.add(parts[2])\n",
    "print(f\"Found {len(jobs)} job folders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART F: Download Results\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 result files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing: 100%|██████████| 8/8 [00:16<00:00,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 249,571 results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# F1: Parse results\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "prefix = f\"{GCS_BATCH_OUTPUT}/\"\n",
    "result_blobs = [b for b in bucket_obj.list_blobs(prefix=prefix) if b.name.endswith('.jsonl')]\n",
    "print(f\"Found {len(result_blobs)} result files\")\n",
    "\n",
    "results = {}\n",
    "for blob in tqdm(result_blobs, desc=\"Parsing\"):\n",
    "    content = blob.download_as_text()\n",
    "    for line in content.strip().split('\\n'):\n",
    "        if not line:\n",
    "            continue\n",
    "        try:\n",
    "            data = json.loads(line)\n",
    "            custom_id = data.get('custom_id', '')\n",
    "            candidates = data.get('response', {}).get('candidates', [])\n",
    "            if candidates:\n",
    "                parts = candidates[0].get('content', {}).get('parts', [])\n",
    "                if parts:\n",
    "                    results[custom_id] = parts[0].get('text', '').strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "print(f\"Parsed {len(results):,} results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PART G: Merge & Upload\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging: 100%|██████████| 249576/249576 [00:00<00:00, 360200.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched: 249,571/249,576 (100.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# G1: Merge - saves as 'scene_prediction' (not 'scene_description')\n",
    "from tqdm import tqdm\n",
    "\n",
    "matched = 0\n",
    "for seq_idx, seq in enumerate(tqdm(sequences, desc=\"Merging\")):\n",
    "    custom_id = f\"{seq_idx}_{seq['comic_no']}_{seq['story_idx']}_{seq['target']['page_no']}_{seq['target']['panel_no']}\"\n",
    "    if custom_id in results:\n",
    "        seq['scene_prediction'] = results[custom_id]  # NEW KEY NAME\n",
    "        matched += 1\n",
    "    else:\n",
    "        seq['scene_prediction'] = None\n",
    "\n",
    "print(f\"Matched: {matched:,}/{len(sequences):,} ({100*matched/len(sequences):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved locally: train_sequences_with_predictions.pkl\n",
      "Uploaded to: gs://harshasekar-comics-data/training_sequences/train_sequences_with_predictions.pkl\n"
     ]
    }
   ],
   "source": [
    "# G2: Save & upload - NEW FILENAME\n",
    "import pickle\n",
    "\n",
    "local_path = WORKDIR / \"train_sequences_with_predictions.pkl\"  # CHANGED\n",
    "with open(local_path, 'wb') as f:\n",
    "    pickle.dump(sequences, f)\n",
    "print(f\"Saved locally: {local_path}\")\n",
    "\n",
    "gcs_path = \"training_sequences/train_sequences_with_predictions.pkl\"  # CHANGED\n",
    "blob = bucket_obj.blob(gcs_path)\n",
    "blob.upload_from_filename(str(local_path))\n",
    "print(f\"Uploaded to: gs://{BUCKET}/{gcs_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample comparison:\n",
      "======================================================================\n",
      "\n",
      "--- Sequence 0 ---\n",
      "ACTUAL Panel 6 text: I'VE BEEN WORKING ON IT FOR DAYS! I MUST GET A BREATH OF AIR AND CLEAR MY HEAD BEFORE I BEGIN MY TES...\n",
      "PREDICTED (Gemini):  The next panel will likely show the \"Weightless Wiggins\" character, the inventor from panels 3-5, testing his new contraption. He might be holding the device he just finished, perhaps a spring-loaded ...\n",
      "\n",
      "\n",
      "--- Sequence 1 ---\n",
      "ACTUAL Panel 6 text: AH, I FEEL BETTER ALREADY! NOW FOR A BRISK WALK TO CALM MY JANGLED NERVES!...\n",
      "PREDICTED (Gemini):  The villain, Weightless Wiggins, having just completed his device, steps outside for some fresh air, perhaps to the rooftop where Plastic Man is currently struggling to understand why Wiggins isn't fa...\n",
      "\n",
      "\n",
      "--- Sequence 2 ---\n",
      "ACTUAL Panel 6 text: And WEIGHTLESS WIGGINS, THUG AND PROFESSIONAL SECOND STORY MAN, WHO IS LURKING NEAR GIMMICK'S HOUSE....\n",
      "PREDICTED (Gemini):  The inventor, having just completed his mysterious contraption and feeling the need for some fresh air, steps outside for a walk. He might be seen strolling down a sidewalk, perhaps with a slight spri...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# G3: Show comparison\n",
    "print(\"Sample comparison:\")\n",
    "print(\"=\"*70)\n",
    "for i in range(3):\n",
    "    seq = sequences[i]\n",
    "    print(f\"\\n--- Sequence {i} ---\")\n",
    "    print(f\"ACTUAL Panel 6 text: {seq['target_text'][:100]}...\")\n",
    "    print(f\"PREDICTED (Gemini):  {seq.get('scene_prediction', 'N/A')[:200]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Done!\n",
    "---\n",
    "\n",
    "## Output File\n",
    "\n",
    "**NEW:** `gs://harshasekar-comics-data/training_sequences/train_sequences_with_predictions.pkl`\n",
    "\n",
    "This file contains:\n",
    "- `scene_prediction`: Gemini's PREDICTION of Panel 6 (without seeing it)\n",
    "\n",
    "## Key Difference from Previous File\n",
    "\n",
    "| Old File | New File |\n",
    "|----------|----------|\n",
    "| `train_sequences_with_descriptions.pkl` | `train_sequences_with_predictions.pkl` |\n",
    "| `scene_description` (Gemini SAW Panel 6) | `scene_prediction` (Gemini did NOT see Panel 6) |\n",
    "| Specific details | Reasonable predictions |\n",
    "| Task mismatch with LLaVA | Task ALIGNED with LLaVA |\n",
    "\n",
    "## Next Step\n",
    "\n",
    "Update fine-tuning notebook to use:\n",
    "- File: `train_sequences_with_predictions.pkl`\n",
    "- Field: `scene_prediction` (instead of `scene_description`)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m136",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m136"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
